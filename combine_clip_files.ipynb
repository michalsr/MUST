{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4205c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from UniCL import configs\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5900869",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicl_model = torch.load('/data/michal5/unicl_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ca0f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(unicl_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb78eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model'])\n"
     ]
    }
   ],
   "source": [
    "print(unicl_model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb881e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import UniCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a54a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from UniCL.model import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0943d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from UniCL.config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4081c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6599dd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--local_rank'], dest='local_rank', nargs=None, const=None, default=None, type=<class 'int'>, choices=None, help='local rank for DistributedDataParallel', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser('UniCL training and evaluation script', add_help=False)\n",
    "parser.add_argument('--cfg', type=str, default='UniCL/configs/unicl_swin_base.yaml', metavar=\"FILE\", help='path to config file', )\n",
    "parser.add_argument(\n",
    "    \"--opts\",\n",
    "    help=\"Modify config options by adding 'KEY VALUE' pairs. \",\n",
    "    default=None,\n",
    "    nargs='+',\n",
    ")\n",
    "\n",
    "# easy config modification\n",
    "parser.add_argument('--batch-size', type=int, help=\"batch size for single GPU\")\n",
    "parser.add_argument('--dataset', type=str, default='imagenet', help='dataset name')       \n",
    "parser.add_argument('--data-path', type=str, help='path to dataset')\n",
    "parser.add_argument('--zip', action='store_true', help='use zipped dataset instead of folder dataset')\n",
    "parser.add_argument('--cache-mode', type=str, default='part', choices=['no', 'full', 'part'],\n",
    "                    help='no: no cache, '\n",
    "                         'full: cache all data, '\n",
    "                         'part: sharding the dataset into nonoverlapping pieces and only cache one piece')\n",
    "parser.add_argument('--resume', help='resume from checkpoint')\n",
    "parser.add_argument('--accumulation-steps', type=int, help=\"gradient accumulation steps\")\n",
    "parser.add_argument('--use-checkpoint', action='store_true',\n",
    "                    help=\"whether to use gradient checkpointing to save memory\")\n",
    "parser.add_argument('--amp-opt-level', type=str, default='O1', choices=['O0', 'O1', 'O2'],\n",
    "                    help='mixed precision opt level, if O0, no amp is used')\n",
    "parser.add_argument('--output', default='output', type=str, metavar='PATH',\n",
    "                    help='root of output folder, the full path is <output>/<model_name>/<tag> (default: output)')\n",
    "parser.add_argument('--tag', help='tag of experiment')\n",
    "parser.add_argument('--eval', action='store_true', help='Perform evaluation only')\n",
    "parser.add_argument('--throughput', action='store_true', help='Test throughput only')\n",
    "parser.add_argument('--debug', action='store_true', help='Perform debug only')\n",
    "\n",
    "# distributed training\n",
    "parser.add_argument(\"--local_rank\", type=int, required=False, help='local rank for DistributedDataParallel')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f5a9dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> merge config from UniCL/configs/unicl_swin_base.yaml\n"
     ]
    }
   ],
   "source": [
    "args, unparsed = parser.parse_known_args()\n",
    "\n",
    "config = get_config(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68119e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model: swin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/rsaas/michal5/anaconda3/envs/must/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "unicl_model = build_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c3b57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('/data/michal5/unicl_model.pth')\n",
    "unicl_model.load_state_dict(state_dict['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44ce327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /srv/condor/execute/dir_76967/pip-req-build-htl3hqd_\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /srv/condor/execute/dir_76967/pip-req-build-htl3hqd_\n",
      "  Resolved https://github.com/openai/CLIP.git to commit d50d76daa670286dd6cacf3bcd80b5e4823fc8e1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in ./anaconda3/envs/must/lib/python3.7/site-packages (from clip==1.0) (6.1.1)\n",
      "Requirement already satisfied: regex in ./anaconda3/envs/must/lib/python3.7/site-packages (from clip==1.0) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/envs/must/lib/python3.7/site-packages (from clip==1.0) (4.64.1)\n",
      "Requirement already satisfied: torch in ./anaconda3/envs/must/lib/python3.7/site-packages (from clip==1.0) (1.10.1)\n",
      "Requirement already satisfied: torchvision in ./anaconda3/envs/must/lib/python3.7/site-packages (from clip==1.0) (0.11.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in ./anaconda3/envs/must/lib/python3.7/site-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: typing_extensions in ./anaconda3/envs/must/lib/python3.7/site-packages (from torch->clip==1.0) (4.4.0)\n",
      "Requirement already satisfied: numpy in ./anaconda3/envs/must/lib/python3.7/site-packages (from torchvision->clip==1.0) (1.19.5)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in ./anaconda3/envs/must/lib/python3.7/site-packages (from torchvision->clip==1.0) (9.3.0)\n"
     ]
    }
   ],
   "source": [
    "!  pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccdf1581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f2fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "def pil_loader(path: str) -> Image.Image:\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "class FileListDataset(Dataset):\n",
    "    def __init__(self, image_file, label_file, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.images = np.load(image_file)\n",
    "        self.labels = np.load(label_file)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = pil_loader(self.images[index])\n",
    "        target = self.labels[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(image)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d92fdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images.npy  train_images.npy  trainval_images.npy\tval_images.npy\r\n",
      "test_labels.npy  train_labels.npy  trainval_labels.npy\tval_labels.npy\r\n"
     ]
    }
   ],
   "source": [
    "! ls /data/michal5/sun397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34fb1151",
   "metadata": {},
   "outputs": [],
   "source": [
    "sun397_eval = FileListDataset('/data/michal5/sun397/test_images.npy', '/data/michal5/sun397/test_labels.npy', preprocess, target_transform=None)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f0675b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21758\n"
     ]
    }
   ],
   "source": [
    "print(len(sun397_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c111dd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set()\n",
    "for l in sun397_eval.labels:\n",
    "    unique_labels.add(l)\n",
    "print(len(list(unique_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8cf96393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open('/shared/rsaas/michal5/must/classes.json','r+') as f:\n",
    "    cl = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87b1926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "clip_text =torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cl['sun397']]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d74f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.utils import accuracy, AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63b1c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "sun397_loader = torch.utils.data.DataLoader(sun397_eval,batch_size=512,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec118a50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AverageMeter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/srv/condor/execute/dir_101822/ipykernel_119295/1220745643.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc_meter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAverageMeter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'AverageMeter' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51dc33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7340ab83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████▎                                                                                                                                                                                     | 1/43 [00:16<11:32, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(3.9062, device='cuda:0')] acc\n",
      "3.90625 avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████████▋                                                                                                                                                                                 | 2/43 [00:32<11:10, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0., device='cuda:0')] acc\n",
      "1.953125 avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████████████▉                                                                                                                                                                             | 3/43 [00:53<12:13, 18.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0., device='cuda:0')] acc\n",
      "1.3020833333333333 avg\n"
     ]
    }
   ],
   "source": [
    "from timm.utils import accuracy, AverageMeter\n",
    "from tqdm import tqdm\n",
    "unicl_model.eval()\n",
    "clip_model.eval()\n",
    "unicl_model = unicl_model.to('cuda:1')\n",
    "correct = 0\n",
    "total = 0\n",
    "acc_meter = AverageMeter()\n",
    "#unicl_embeddings = unicl_model.get_embeddings(unique_labels)\n",
    "\n",
    "for (num,(images,labels)) in enumerate(tqdm(sun397_loader)):\n",
    "\n",
    "    #print(images.size())\n",
    "    #unicl \n",
    "    with torch.no_grad():\n",
    "        text_features = clip_model.encode_text(clip_text)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        images = images.to('cuda:1')\n",
    "        labels = labels.to('cuda:1')\n",
    "        feat_img = unicl_model.encode_image(images)\n",
    "#         #print(feat_img.size())\n",
    "        text_features = text_features.to('cuda:1')\n",
    "        unicl_model_output = unicl_model.logit_scale.exp() * feat_img.half() @ text_features.t()\n",
    "# #         #clip \n",
    "        text_features = text_features.to('cuda:0')\n",
    "        images = images.to('cuda:0')\n",
    "        labels = labels.to('cuda:0')\n",
    "        image_features = clip_model.encode_image(images)\n",
    "        #text_features = clip_model.encode_text(clip_text)''\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        logit_scale = clip_model.logit_scale.exp()\n",
    "\n",
    "        similarity = logit_scale * image_features @ text_features.t()\n",
    "        #values, ind = similarity.topk(1)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#         temp_c = 0\n",
    "#         for i,l in zip(ind,labels):\n",
    "#             if i.item() == l.item():\n",
    "#                 temp_c += 1\n",
    "#         print(temp_c,'temp')\n",
    "            \n",
    "#         print(labels.size(),'labels size')\n",
    "#         c =  (ind == labels)\n",
    "#         print(c,'new correct')\n",
    "#         correct += c.sum().item()\n",
    "#         print(correct, 'updated correct')\n",
    "#         print(ind.size(),ind.size()[0],ind.size()[1])\n",
    "        \n",
    "# #         for i,l in zip(ind,labels):\n",
    "# #             print(i.item(),l.item(),'hellp')\n",
    "# #             if i == l:\n",
    "# #                 print('yes')\n",
    "# #                 correct+=1\n",
    "# # #         temp_acc = (ind==labels).sum().item()\n",
    "# # #         correct += temp_acc \n",
    "# #         print(ind.size()[1],'size')\n",
    "#         total+= ind.size()[0]\n",
    "#         print(total)\n",
    "        #print(temp_acc,'temp acc')\n",
    "        unicl_model_output = unicl_model_output.to('cuda:0')\n",
    "        combined_output = (unicl_model_output+similarity)\n",
    "        #combined_output = similarity\n",
    "        #print(similarity.softmax(dim=-1).topk(0),labels)\n",
    "        #combined_output = com\n",
    "        acc = accuracy(combined_output,labels,topk=(1,))\n",
    "        print(acc,'acc')\n",
    "        acc_meter.update(acc[0].item(), labels.size(0))\n",
    "        print(acc_meter.avg,'avg')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33b19bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.245959051724138\n"
     ]
    }
   ],
   "source": [
    "print(acc_meter.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac156b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
